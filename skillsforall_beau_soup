print("----------------------------START PROGRAM----------------------------")

from selenium import webdriver
from selenium.webdriver.common.by import By
from selenium.webdriver.common.keys import Keys
from selenium.webdriver.support.ui import WebDriverWait
from selenium.webdriver.support import expected_conditions as EC
from selenium.webdriver.common.action_chains import ActionChains
import time
from bs4 import BeautifulSoup
import requests
import re
import csv
# as per recommendation from @freylis, compile once only
CLEANR = re.compile('<.*?>') 

#initialize CSV writer
output = open("./skillsforall_data.csv", "w")
writer = csv.writer(output)
#set header
header = ["Course Title", "Course Content"]
writer.writerow(header)

#html stripper
def cleanhtml(raw_html):
  cleantext = re.sub(CLEANR, '', raw_html)
  return cleantext

#see https://www.geeksforgeeks.org/beautifulsoup-scraping-link-from-html/

#note: might be easier here to use safari, or to disable cookies
driver = webdriver.Chrome("/Users/ethanchen/Downloads/chromedriver")

#----------begin login----------
email = "ethanctrooer@yahoo.com"
password = "Zippo123!"

driver.get("https://skillsforall.com")
WebDriverWait(driver,10).until(EC.element_to_be_clickable(("class name","userIconsize--1lxI6")))
driver.find_element("class name", "userIconsize--1lxI6").click()
WebDriverWait(driver,10).until(EC.element_to_be_clickable(("id","username")))

driver.find_element("id", "username").send_keys(email)
driver.find_element("id", "password").send_keys(password)
driver.find_element("id", "password").send_keys(Keys.RETURN)

#----------end login----------

#----------begin navigate to course page----------

WebDriverWait(driver,100).until(EC.element_to_be_clickable(("class name","imgPlay--2JLAG.cusAccBtn--btGrR")))
driver.find_element("class name", "imgPlay--2JLAG.cusAccBtn--btGrR").click()
time.sleep(2)

#----------end navigate to course page----------

# function to extract html document from given url
def getHTMLdocument(url):
      
    # request for HTML document of given url
    response = requests.get(url)
      
    # response will be provided in JSON format
    return response.text

# assign required credentials
# assign URL
  
# create document
html_document = driver.find_element('xpath', '//html').get_attribute('outerHTML')
  
# create soap object
soup = BeautifulSoup(html_document, 'lxml')

#NOTE: only does basic clean, for NLP cleaning use in model
def basic_text_clean(soup_text: str):
    clean_soup = re.sub(r'\s{2,999}', ' ', cleanhtml(str(soup_text)))
    return clean_soup
#end basic_test_clean

#get html from current page, write page text to file
#will not get text from non-standard stuff, like <ul> & <li> elements. see linkedin_jobextract_v2 for this
#NOTE: not built to take a link b/c was already coded below not to need, pretty bad design
def get_html_and_write():

    time.sleep(5) #not great
    driver.execute_script("window.scrollTo(0, document.body.scrollHeight);")
    
    html_document_source = driver.find_element('xpath', '//html').get_attribute('outerHTML')
    soup_source = BeautifulSoup(html_document_source, 'lxml')
    soup_text = soup_source.find_all(['p', 'dir'])

    clean_text = basic_text_clean(soup_text)
    course_title = basic_text_clean(soup_source.find_all(['title']))

    print(clean_text)
    print(course_title)

    to_write = [course_title, clean_text]

    writer.writerow(to_write)

    #NOTE: NEW CODE
    #if driver.find_element("")

#end get_html_and_write

#must already be on a course page
def get_iframes():
    module_iframes = []
    #modules = driver.find_elements(By.CSS_SELECTOR, 'div[type="vertical"]')
    buttons = driver.find_elements(By.CSS_SELECTOR, 'button[role="button"]')
    #print(modules)
    #print(buttons)
    buttons.pop(0) #remove the intro to course header
    buttons.pop(0) #remove the course navigation tutorial
    for button in buttons:
        WebDriverWait(driver,10).until(EC.element_to_be_clickable((button)))
        #https://stackoverflow.com/questions/37879010/selenium-debugging-element-is-not-clickable-at-point-x-y
        #button.click()
        ActionChains(driver).move_to_element(button).click(button).perform() #NOTE: MUST be focused on window when this happens, or it fails
        #WebDriverWait(driver, 10).until(EC.visibility_of(('xpath', '//iframe'))) #visibility_of
        time.sleep(7)
        #driver.execute_script("arguments[0].click();", module)
        #module.send_keys("\n")
        #iframes = driver.find_elements(By.CSS_SELECTOR, 'iframe[src]')
        html_document = driver.find_element('xpath', '//html').get_attribute('outerHTML')
        soup = BeautifulSoup(html_document, 'lxml')
        soup_iframes = soup.find_all('iframe')
        module_iframes.append(soup_iframes[1])
        #print(iframes.current_url)
    return module_iframes
#end get_iframes


#extract text from a link (specifically a course)
#elem is a number set to grab that specific part of the course
#click on all module links first then run this function
def get_from_iframe(link):
    #print(i)
    #print(type(i))
    source = link.get('src')
    #print(i.get('src'))
    if "skillsforall" in source:
        driver.get(source)
        course_parts = [] #this is a list of clickable elements
        course_part = ""
        #time.sleep(7) #this bad
        try:
            WebDriverWait(driver,3).until(EC.element_to_be_clickable(("class name","introoutro__action.btn-action.introoutro__skip")))
            driver.find_element("class name", "introoutro__action.btn-action.introoutro__skip").click()
        except Exception as ex:
            print("error 1")
            template = "An exception of type {0} occurred. Arguments:\n{1!r}"
            message = template.format(type(ex).__name__, ex.args)
            print(message)
        #not sure if this is needed
        try:
            WebDriverWait(driver,3).until(EC.element_to_be_clickable(("class name","btn-text.notify__btn.notify__btn-prompt.js-notify-btn-prompt")))
            #driver.find_element("class name", "btn-text.notify__btn.notify__btn-prompt.js-notify-btn-prompt").click()
            #trying to click no here
            driver.find_element(By.CSS_SELECTOR, '[aria-label="No"]').click()
        except Exception as ex:
            print("error 2")
            template = "An exception of type {0} occurred. Arguments:\n{1!r}"
            message = template.format(type(ex).__name__, ex.args)
            print(message)
        #main block, for navigation page per module
        try:
            WebDriverWait(driver,5).until(EC.element_to_be_clickable(("class name","menu-item__title.boxmenu-item__title")))
            #course_parts = driver.find_elements("class name", "menu-item__title.boxmenu-item__title")
            course_part = driver.find_element("class name", "menu-item__title.boxmenu-item__title")
            #/html/body/div[4]/div/div[2]/div/div[3]/div/div[1]/div/div/div/div[1]
            #WebDriverWait(driver,5).until(EC.element_to_be_clickable(("xpath","menu-item__title.boxmenu-item__title")))
            #driver.find_element("class name", "menu-item__title.boxmenu-item__title").click()
        except Exception as ex:
            print("error 3")
            template = "An exception of type {0} occurred. Arguments:\n{1!r}"
            message = template.format(type(ex).__name__, ex.args)
            print(message)

        #each part in course_parts is attatched to old window
        #easiest way to do this so far is to recurse, get each time, move to next part
        #TODO: HELLLA inefficient. find new way to do this

        #set part to the one in this iteration
        #part = course_parts[part_num]

        #part.click()
        course_part.click()

        while True:
            try:
                get_html_and_write()
                WebDriverWait(driver,3).until(EC.element_to_be_clickable((By.CSS_SELECTOR, '[aria-label="Next Page Incomplete"]')))
                driver.find_element(By.CSS_SELECTOR, '[aria-label="Next Page Incomplete"]').click()
            except Exception as ex:
                print("error 4")
                template = "An exception of type {0} occurred. Arguments:\n{1!r}"
                message = template.format(type(ex).__name__, ex.args)
                print(message)
                break
        #end of while loop
        print("end of iframe")
        #NOTE: so fuckin jank
        
#end get_from_iframe

time.sleep(2)

iframes = get_iframes()

#iframes = soup.find_all('iframe')
#get_from_iframe(iframes[1]) #or pass in all in for loop, func built to protect (poorly)

for iframe in iframes:
    get_from_iframe(iframe)
#end for loop

#, src=lambda s: all(word in s for word in ('skillsforall', 'true')))
#https://stackoverflow.com/questions/23028664/python-beautifulsoup-iframe-document-html-extract
#https://stackoverflow.com/questions/54522364/python-beautifulsoup-scrape-web-content-inside-iframes

#print(iframes)

writer.close()


print("----------------------------END PROGRAM----------------------------")

#problem statement
#multiple approaches from NLP standpoint
#basic results
#next